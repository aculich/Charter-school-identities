{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: UTF-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing & Categorizing HTML from `wget` run!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import os, re, fnmatch # for navigating file trees and working with strings\n",
    "import csv # for reading in CSV files\n",
    "from glob import glob,iglob # for finding files within nested folders\n",
    "import json, pickle # For saving a loading dictionaries, etc. from file with JSON and pickle formats\n",
    "from datetime import datetime # For timestamping files\n",
    "import sys # For working with user input\n",
    "from nltk.stem.porter import PorterStemmer # an approximate method of stemming words\n",
    "stemmer = PorterStemmer()\n",
    "from nltk import word_tokenize, sent_tokenize # widely used text tokenizer\n",
    "import urllib, urllib.request # for testing pages\n",
    "from unicodedata import normalize\n",
    "\n",
    "# Import parser\n",
    "from bs4 import BeautifulSoup # BS reads and parses even poorly/unreliably coded HTML \n",
    "from bs4.element import Comment # helps with detecting inline/junk tags when parsing with BS\n",
    "import lxml # for fast HTML parsing with BS\n",
    "bsparser = \"lxml\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Set script options\n",
    "\n",
    "Debug = True # Set to \"True\" for extra progress reports while algorithms run\n",
    "notebook = True # Use different file paths depending on whether files are being accessed from shell (False) or within a Jupyter notebook (True)\n",
    "usefile = False # Set to \"True\" if loading from file a dicts_list to add to. Confirms with user input first!\n",
    "workstation = False # If working from office PC\n",
    "\n",
    "if notebook:\n",
    "    usefile = False # Prompting user for input file is only useful in command-line\n",
    "\n",
    "inline_tags = [\"b\", \"big\", \"i\", \"small\", \"tt\", \"abbr\", \"acronym\", \"cite\", \"dfn\",\n",
    "               \"em\", \"kbd\", \"strong\", \"samp\", \"var\", \"bdo\", \"map\", \"object\", \"q\",\n",
    "               \"span\", \"sub\", \"sup\"] # this list helps with eliminating junk tags when parsing HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Set directories\n",
    "\n",
    "if workstation and notebook:\n",
    "    dir_prefix = \"C:\\\\Users\\\\Jaren\\\\Documents\\\\Charter-school-identities\\\\\"\n",
    "elif notebook:\n",
    "    dir_prefix = \"/home/jovyan/work/\"\n",
    "else:\n",
    "    dir_prefix = \"/vol_b/data/\"\n",
    "\n",
    "example_page = \"https://westlakecharter.com/about/\"\n",
    "example_schoolname = \"TWENTY-FIRST_CENTURY_NM\"\n",
    "\n",
    "if workstation and notebook:\n",
    "    micro_sample13 = dir_prefix + \"data\\\\micro-sample13_coded.csv\" #data location for random micro-sample of 300 US charter schools\n",
    "    full_schooldata = dir_prefix + \"data\\\\charter_URLs_2014.csv\" #data location for 2014 population of US charter schools\n",
    "    example_file = dir_prefix + \"data\\\\example_file.html\" #example_folder + \"21stcenturypa.com/wp/default?page_id=27.tmp.html\"\n",
    "    dicts_dir = dir_prefix + \"dicts\\\\\" # Directory in which to find & save dictionary files\n",
    "    save_dir = dir_prefix + \"data\\\\\" # Directory in which to save data files\n",
    "\n",
    "else:\n",
    "    wget_dataloc = dir_prefix + \"wget/parll_wget/\" #data location for schools downloaded with wget in parallel (requires server access)\n",
    "    example_folder = wget_dataloc + \"TWENTY-FIRST_CENTURY_NM/\"\n",
    "    example_file = dir_prefix + \"wget/example_file.html\" #example_folder + \"21stcenturypa.com/wp/default?page_id=27.tmp.html\"\n",
    "\n",
    "    micro_sample13 = dir_prefix + \"Charter-school-identities/data/micro-sample13_coded.csv\" #data location for random micro-sample of 300 US charter schools\n",
    "    full_schooldata = dir_prefix + \"Charter-school-identities/data/charter_URLs_2014.csv\" #data location for 2014 population of US charter schools\n",
    "    dicts_dir = dir_prefix + \"Charter-school-identities/dicts/\" # Directory in which to find & save dictionary files\n",
    "    save_dir = dir_prefix + \"Charter-school-identities/data/\" # Directory in which to save data files\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input file, if any\n",
    "if usefile and not notebook:\n",
    "    print(\"\\nWould you like to load from file a list of dictionaries to add to? (Y/N)\")\n",
    "    answer = input()\n",
    "    if answer == \"Y\":\n",
    "        print(\"Please indicate file path for dictionary list file.\")\n",
    "        answer2 = input()\n",
    "        if os.path.exists(answer2):\n",
    "            input_file = answer2\n",
    "            usefile = True\n",
    "        else:\n",
    "            print(\"Invalid file path. Aborting script.\")\n",
    "            sys.exit()\n",
    "\n",
    "    elif answer == \"N\":\n",
    "        print(\"OK! This script will create a new file for this list of dictionaries.\")\n",
    "        usefile = False\n",
    "    \n",
    "    else:\n",
    "        print(\"Response not interpretable. Aborting script.\")\n",
    "        sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Define (non-parsing) helper functions\n",
    "\n",
    "def get_vars(data):\n",
    "    \"\"\"Defines variable names based on the data source called.\"\"\"\n",
    "    \n",
    "    if data==full_schooldata:\n",
    "        URL_variable = \"TRUE_URL\"\n",
    "        NAME_variable = \"SCH_NAME\"\n",
    "        ADDR_variable = \"ADDRESS\"\n",
    "    \n",
    "    elif data==micro_sample13:\n",
    "        URL_variable = \"URL\"\n",
    "        NAME_variable = \"SCHNAM\"\n",
    "        ADDR_variable = \"ADDRESS\"\n",
    "    \n",
    "    else:\n",
    "        try:\n",
    "            print(\"Error processing variables from data file \" + str(data) + \"!\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"ERROR: No data source established!\\n\")\n",
    "    \n",
    "    return(URL_variable,NAME_variable,ADDR_variable)\n",
    "\n",
    "\n",
    "def tag_visible(element):\n",
    "    \"\"\"Returns false if a web element has a non-visible tag, \n",
    "    i.e. one site visitors wouldn't actually read--and thus one we don't want to parse\"\"\"\n",
    "    \n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def webtext_from_files(datalocation):\n",
    "    \"\"\"Concatenate and return a single string from all webtext (with .txt format) in datalocation\"\"\"\n",
    "    \n",
    "    string = \"\"\n",
    "    for root, dirs, files in os.walk(datalocation):\n",
    "        for file in files:\n",
    "            if file.endswith(\".txt\"):\n",
    "                fileloc = open(datalocation+file, \"r\")\n",
    "                string = string + (fileloc.read())\n",
    "    return string\n",
    "\n",
    "\n",
    "def remove_spaces(file_path):\n",
    "    \"\"\"Remove spaces from text file at file_path\"\"\"\n",
    "    \n",
    "    words = [x for x in open(file_path).read().split() if x != \"\"]\n",
    "    text = \"\"\n",
    "    for word in words:\n",
    "        text += word + \" \"\n",
    "    return text\n",
    "\n",
    "\n",
    "def save_to_file(dicts_list, file, mode):\n",
    "    \"\"\"Saves dicts_list to file using JSON or pickle format (whichever was specified).\"\"\"\n",
    "    \n",
    "    file = str(file)\n",
    "    \n",
    "    try:\n",
    "        if mode==\"JSON\":\n",
    "            if not file.endswith(\".json\"):\n",
    "                file += \".json\"\n",
    "            with open(file, 'wb') as outfile:\n",
    "                json.dump(dicts_list, outfile)\n",
    "            #pickle.dump(dicts_list, outfile)\n",
    "                print(dicts_list + \" successfully saved to \" + file + \"in JSON format!\\n\")\n",
    "\n",
    "        elif mode==\"pickle\":\n",
    "            if not file.endswith(\".pickle\"):\n",
    "                file += \".pickle\"\n",
    "            with open(file, 'wb') as outfile:\n",
    "                pickle.dump(dicts_list, outfile)\n",
    "                print(dicts_list + \" successfully saved to \" + file + \" in pickle format!\\n\")\n",
    "\n",
    "        else:\n",
    "            print(\"ERROR! Save failed due to improper arguments. These are: file, object to be saved, and file format to save in.\\n\\\n",
    "                  Specify either 'JSON' or 'pickle' as third argument ('mode' or file format) when calling this function.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "\n",
    "def load_file(file):\n",
    "    \"\"\"Loads dicts_list (or whatever) from file, using either JSON or pickle format. \n",
    "    The created object should be assigned when called.\"\"\"\n",
    "    \n",
    "    file = str(file)\n",
    "    \n",
    "    with open(file,'rb') as infile:\n",
    "        if file.endswith(\".json\"):\n",
    "            var = json.load(infile)\n",
    "        if file.endswith(\".pickle\"):\n",
    "            var = pickle.load(infile)\n",
    "        print(file + \" successfully loaded!\\n\")\n",
    "    return var\n",
    "\n",
    "\n",
    "def load_dict(custom_dict, file_path):\n",
    "    \"\"\"Loads in a dictionary. Adds each entry from the dict at file_path to the defined set custom_dict (the input), \n",
    "    which can also be an existing dictionary. This allows the creation of combined dictionaries!\"\"\"\n",
    "\n",
    "    with open(file_path) as file_handler:\n",
    "        line = file_handler.readline()\n",
    "        while line:\n",
    "            custom_dict.add(stemmer.stem(line.replace(\"\\n\", \"\"))) # Add line after stemming dictionary entries and eliminating newlines\n",
    "            line = file_handler.readline() # Look for anything else in that line, add that too\n",
    "    return custom_dict\n",
    "\n",
    "\n",
    "def list_files(folder_path, extension):\n",
    "    \"\"\"Outputs a list of every file in folder_path or its subdirectories that has a specified extension.\n",
    "    Prepends specified extension with '.' if it doesn't start with it already.\n",
    "    If no extension is specified, it just returns all files in folder_path.\"\"\"\n",
    "    \n",
    "    matches = []\n",
    "    if extension:\n",
    "        extension = str(extension) # Coerce to string, just in case\n",
    "    \n",
    "    if extension and not extension.startswith(\".\"):\n",
    "        extension = \".\" + extension\n",
    "    \n",
    "    for dirpath,dirnames,filenames in os.walk(folder_path):\n",
    "        if extension:\n",
    "            for filename in fnmatch.filter(filenames, \"*\" + extension): # Use extension to filter list of files\n",
    "                matches.append(os.path.join(dirpath,filename))\n",
    "        else:\n",
    "                matches.append(os.path.join(dirpath,filename)) # If no extension, just take all files\n",
    "    return matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "List of keywords:\n",
      " ['creed', 'valu', 'our stori', 'school stori', 'our school', 'structur', 'our purpos', 'approach', 'philosoph', 'background', 'doors open', 'establish', 'believ', 'curriculum', 'we began', 'academ', 'system', 'histori', 'model', 'curricular', 'school open', 'ideal', 'our id', 'who we ar', 'profil', 'the stori', 'skill', 'about u', 'our school began', 'highlight', 'found', 'pedagog', 'our caus', 'purpos', 'pedagogi', 'moral', 'direct', 'mission', 'vision', 'belief', 'philosophi', 'principl', 'method', 'credo', 'our ident']\n"
     ]
    }
   ],
   "source": [
    "# ### Set parsing keywords\n",
    "\n",
    "keywords = ['values', 'academics', 'skills', 'purpose',\n",
    "                       'direction', 'mission', 'vision', 'vision', 'mission', 'our purpose',\n",
    "                       'our ideals', 'ideals', 'our cause', 'curriculum','curricular',\n",
    "                       'method', 'pedagogy', 'pedagogical', 'approach', 'model', 'system',\n",
    "                       'structure','philosophy', 'philosophical', 'beliefs', 'believe',\n",
    "                       'principles', 'creed', 'credo', 'values','moral', 'history', 'our story',\n",
    "                       'the story', 'school story', 'background', 'founding', 'founded',\n",
    "                       'established','establishment', 'our school began', 'we began',\n",
    "                       'doors opened', 'school opened', 'about us', 'our school', 'who we are',\n",
    "                       'our identity', 'profile', 'highlights']\n",
    "\n",
    "mission_keywords = ['mission','vision', 'vision:', 'mission:', 'our purpose', 'our ideals', 'ideals:', 'our cause', 'cause:', 'goals', 'objective']\n",
    "curriculum_keywords = ['curriculum', 'curricular', 'program', 'method', 'pedagogy', 'pedagogical', 'approach', 'model', 'system', 'structure']\n",
    "philosophy_keywords = ['philosophy', 'philosophical', 'beliefs', 'believe', 'principles', 'creed', 'credo', 'value',  'moral']\n",
    "history_keywords = ['history', 'story','our story', 'the story', 'school story', 'background', 'founding', 'founded', 'established', 'establishment', 'our school began', 'we began', 'doors opened', 'school opened']\n",
    "about_keywords =  ['about us', 'our school', 'who we are', 'overview', 'general information', 'our identity', 'profile', 'highlights']\n",
    "\n",
    "mission_keywords = set(stemmer.stem(word) for word in mission_keywords)\n",
    "curriculum_keywords = set(stemmer.stem(word) for word in curriculum_keywords)\n",
    "philosophy_keywords = set(stemmer.stem(word) for word in philosophy_keywords)\n",
    "history_keywords = set(stemmer.stem(word) for word in history_keywords)\n",
    "about_keywords =  set(stemmer.stem(word) for word in about_keywords)\n",
    "keys_dict = set(stemmer.stem(key) for key in keywords)\n",
    "    \n",
    "if Debug:\n",
    "    print(\"\\nList of keywords:\\n\", list(keys_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481 entries loaded into the combined ideology dictionary.\n",
      "First 10 elements of combined ideology dictionary are:\n",
      " ['abstract think', 'abstract thought', 'account', 'achievement gain', 'achievement gap', 'activi', 'adapt', 'agricult', 'anim', \"another's sho\"]\n"
     ]
    }
   ],
   "source": [
    "# To use with filtering, create combined dictionary for ideologies:\n",
    "\n",
    "ideol_dict = set()\n",
    "ideol_dict = load_dict(ideol_dict, dicts_dir + \"ess_dict.txt\")\n",
    "ideol_dict = load_dict(ideol_dict, dicts_dir + \"prog_dict.txt\")\n",
    "\n",
    "if Debug:\n",
    "    print(len(ideol_dict), \"entries loaded into the combined ideology dictionary.\")\n",
    "    list_dict = list(ideol_dict)\n",
    "    list_dict.sort(key = lambda x: x.lower())\n",
    "    print(\"First 10 elements of combined ideology dictionary are:\\n\", list_dict[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'Contact Us: 2680 Mabry Dr. 95835 (916) 567-5760 | admin@westlakecharter.com', 'Staff Login', 'About', 'Administration & Support Staff  Employment Opportunities  Business Services  Admission & Enrollment Information  Supply Donations  Hot Lunch Payments  Hot Lunch Menu', 'Board', 'Board Policies  Board Committees  Board Documents', 'WCS', 'Infinite Campus Login  School Dismissal Manager  Ways to Westlake', 'Teachers  BASE  WAVE', 'Meetings  Contact Us  Volunteer Opportunities  Volunteer Hours  Log Volunteer Hours  Spirit Store', 'Calendars', '17/18 School Calendar  18/19 School Calendar', 'About', 'About  Aimee Wells  2013-09-18T18:36:35+00:00', 'About Westlake Charter Schools  Key School Features', 'International Focus  Thematic Curriculum  Artistic Development  Foreign Language Instruction  School-Wide Enrichment Model', 'Core Values', 'Respect  Excellence  Responsibility  Reflective  Global Perspective  Stewardship  Perseverance  Inquisitive  Joyful Learning  Gratitude', 'Calendars, Schedules, Handbooks and More', 'Family Handbook  2017/18 School Calendar  2017/18 Bell Schedule  WCS Charter  Strategic Plan', 'Westlake Charter School is a K-8th grade public elementary school created by parents and educators in Natomas. We opened our doors in 2005 and continue to grow serving more and more students each year. WCS’s primary mission is to demonstrate what is possible when school and community collaborate to create inspiring adults with the academic and social-emotional readiness to lead as Global Citizens.  Westlake Charter School students are EXPLORERS! Our curriculum focuses on diversity and appreciation of different cultures, while promoting academic excellence and foreign language acquisition. We offer various specialty classes to all of our students including Art, Physical Education, and Spanish. Our middle school program focuses on Math, Science and Technology and is executed through the use of technology. Westlake Charter School has small class sizes of approximately 22-24 students in K-3rd grade and 29 students in 4th-8th grade.  First time visitors to Westlake Charter School often remark, “What a warm and inviting school!” Creating a school that is caring and open is absolutely critical in working successfully with our children and families. Students who feel safe, secure, and appreciated gain a love of learning and will be successful scholars.  Westlake Charter School’s professional staff is relentless in seeking and trying research-based best practices that engage every student. Our lessons are hands-on and differentiated to meet the diverse needs of all students. Our teachers display a never-ending commitment to improving their own expertise. Furthermore, we would not be as successful without the support and involvement of our parents. Our parent group is outstanding in helping us achieve our goals by volunteering their time in class, fundraising for our unique programs, and providing endless words of encouragement and support. Our school team is second to none!', 'Recent', 'Westlake Weekly – January 5, 2017  January 5th, 2018', 'Westlake Weekly – December 15, 2017  December 15th, 2017', 'Westlake Weekly – December 8, 2017  December 8th, 2017', 'Westlake Weekly – December 1, 2017  December 1st, 2017', 'Westlake Weekly – November 17, 2017  November 17th, 2017', 'Westlake Weekly – November 9, 2017  November 9th, 2017', 'Contact Info', '2680 Mabry Dr. 95835  Phone: (916) 567-5760  Fax: (916) 567-5769  Email: admin@westlakecharter.com', 'Copyright 2015 Westlake Charter | All Rights Reserved | Contact Us', ''] \n",
      "\n",
      " ['Contact Us: 2680 Mabry Dr. 95835 (916) 567-5760', '|', 'admin@westlakecharter.com', 'Staff Login', 'About', 'Administration & Support Staff', 'Employment Opportunities', 'Business Services', 'Admission & Enrollment Information', 'Supply Donations', 'Hot Lunch Payments', 'Hot Lunch Menu', 'Board', 'Board Policies', 'Board Committees', 'Board Documents', 'WCS', 'Infinite Campus Login', 'School Dismissal Manager', 'Ways to Westlake', 'Teachers', 'BASE', 'WAVE', 'Meetings', 'Contact Us', 'Volunteer Opportunities', 'Volunteer Hours', 'Log Volunteer Hours', 'Spirit Store', 'Calendars', '17/18 School Calendar', '18/19 School Calendar', 'About', 'About', 'Aimee Wells', '2013-09-18T18:36:35+00:00', 'About Westlake Charter Schools', 'Key School Features', 'International Focus', 'Thematic Curriculum', 'Artistic Development', 'Foreign Language Instruction', 'School-Wide Enrichment Model', 'Core Values', 'Respect', 'Excellence', 'Responsibility', 'Reflective', 'Global Perspective', 'Stewardship', 'Perseverance', 'Inquisitive', 'Joyful Learning', 'Gratitude', 'Calendars, Schedules, Handbooks and More', 'Family Handbook', '2017/18 School Calendar', '2017/18 Bell Schedule', 'WCS Charter', 'Strategic Plan', 'Westlake Charter School is a K-8th grade public elementary school created by parents and educators in Natomas. We opened our doors in 2005 and continue to grow serving more and more students each year. WCS’s primary mission is to demonstrate what is possible when school and community collaborate to create inspiring adults with the academic and social-emotional readiness to lead as Global Citizens.', 'Westlake Charter School students are EXPLORERS! Our curriculum focuses on diversity and appreciation of different cultures, while promoting academic excellence and foreign language acquisition. We offer various specialty classes to all of our students including Art, Physical Education, and Spanish. Our middle school program focuses on Math, Science and Technology and is executed through the use of technology. Westlake Charter School has small class sizes of approximately 22-24 students in K-3rd grade and 29 students in 4th-8th grade.', 'First time visitors to Westlake Charter School often remark, “What a warm and inviting school!” Creating a school that is caring and open is absolutely critical in working successfully with our children and families. Students who feel safe, secure, and appreciated gain a love of learning and will be successful scholars.', 'Westlake Charter School’s professional staff is relentless in seeking and trying research-based best practices that engage every student. Our lessons are hands-on and differentiated to meet the diverse needs of all students. Our teachers display a never-ending commitment to improving their own expertise. Furthermore, we would not be as successful without the support and involvement of our parents. Our parent group is outstanding in helping us achieve our goals by volunteering their time in class, fundraising for our unique programs, and providing endless words of encouragement and support. Our school team is second to none!', 'Recent', 'Westlake Weekly – January 5, 2017', 'January 5th, 2018', 'Westlake Weekly – December 15, 2017', 'December 15th, 2017', 'Westlake Weekly – December 8, 2017', 'December 8th, 2017', 'Westlake Weekly – December 1, 2017', 'December 1st, 2017', 'Westlake Weekly – November 17, 2017', 'November 17th, 2017', 'Westlake Weekly – November 9, 2017', 'November 9th, 2017', 'Contact Info', '2680 Mabry Dr. 95835', 'Phone: (916) 567-5760', 'Fax: (916) 567-5769', 'Email: ', 'admin@westlakecharter.com', 'Copyright 2015 Westlake Charter | All Rights Reserved | ', 'Contact Us']\n"
     ]
    }
   ],
   "source": [
    "# ### Compare parsing by newlines vs. by HTML tags\n",
    "\n",
    "def parseurl_by_newlines(urlstring):\n",
    "    \"\"\"Uses BS to parse HTML from a given URL and looks for three newlines to separate chunks of text.\"\"\"\n",
    "    \n",
    "    # Read HTML from a given url:\n",
    "    with urllib.request.urlopen(urlstring) as url:\n",
    "        s = url.read()\n",
    "    \n",
    "    # Parse raw text from website body:\n",
    "    soup = BeautifulSoup(s, bsparser)\n",
    "    texts = soup.findAll(text=True)\n",
    "    visible_texts = filter(tag_visible, texts)  \n",
    "    webtext = u\" \".join(t.strip() for t in visible_texts)\n",
    "    \n",
    "    return re.split(r'\\s{3,}', webtext)\n",
    "\n",
    "\n",
    "def parseurl_by_tags(urlstring):\n",
    "    \"\"\"Cleans HTML by removing inline tags, ripping out non-visible tags, \n",
    "    replacing paragraph tags with a random string, and finally using this to separate HTML into chunks.\n",
    "    Reads in HTML from the web using a given website address, urlstring.\"\"\"\n",
    "    \n",
    "    with urllib.request.urlopen(urlstring) as url:\n",
    "        HTML_page = url.read()\n",
    "\n",
    "    random_string = \"\".join(map(chr, os.urandom(75))) # Create random string for tag delimiter\n",
    "    soup = BeautifulSoup(HTML_page, bsparser)\n",
    "    \n",
    "    [s.extract() for s in soup(['style', 'script', 'head', 'title', 'meta', '[document]'])] # Remove non-visible tags\n",
    "    for it in inline_tags:\n",
    "        [s.extract() for s in soup(\"</\" + it + \">\")] # Remove inline tags\n",
    "    \n",
    "    visible_text = soup.getText(random_string).replace(\"\\n\", \"\") # Replace \"p\" tags with random string, eliminate newlines\n",
    "    visible_text = list(elem.replace(\"\\t\",\"\") for elem in visible_text.split(random_string)) # Split text into list using random string while eliminating tabs\n",
    "    visible_text = list(filter(lambda vt: vt.split() != [], visible_text)) # Eliminate empty elements\n",
    "    # Consider joining list elements together with newline in between by prepending with: \"\\n\".join\n",
    "    \n",
    "    return(visible_text)\n",
    "\n",
    "\n",
    "# Text chunking accuracy of parsing by tags is superior to parsing by newlines:\n",
    "# Compare each of these with the browser-displayed content of example_page:\n",
    "if Debug:\n",
    "    print(parseurl_by_newlines(example_page),\"\\n\\n\",parseurl_by_tags(example_page))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Define parsing helper functions\n",
    "\n",
    "def parsefile_by_tags(HTML_file):\n",
    "    \n",
    "    \"\"\"Cleans HTML by removing inline tags, ripping out non-visible tags, \n",
    "    replacing paragraph tags with a random string, and finally using this to separate HTML into chunks.\n",
    "    Reads in HTML from storage using a given filename, HTML_file.\"\"\"\n",
    "\n",
    "    random_string = \"\".join(map(chr, os.urandom(75))) # Create random string for tag delimiter\n",
    "    soup = BeautifulSoup(open(HTML_file), bsparser)\n",
    "    \n",
    "    [s.extract() for s in soup(['style', 'script', 'head', 'title', 'meta', '[document]'])] # Remove non-visible tags\n",
    "    for it in inline_tags:\n",
    "        [s.extract() for s in soup(\"</\" + it + \">\")] # Remove inline tags\n",
    "    \n",
    "    visible_text = soup.getText(random_string).replace(\"\\n\", \"\") # Replace \"p\" tags with random string, eliminate newlines\n",
    "    visible_text = list(elem.replace(\"\\t\",\"\").replace(u'\\xa0', u' ') for elem in visible_text.split(random_string)) # Split text into list using random string while eliminating tabs and unicode; OR: normalize(\"NFKC\", elem) \n",
    "    visible_text = list(filter(lambda vt: vt.split() != [], visible_text)) # Eliminate empty elements and unicode. \n",
    "    # Consider joining list elements together with newline in between by prepending with: \"\\n\".join\n",
    "\n",
    "    return(visible_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of parsefile_by_tags:\n",
      "\n",
      " ['About', 'Administration', 'Admissions', 'News', 'Charter School Information', 'Location', 'Frequently Asked Questions', 'Photos/Videos', 'School Facebook Page', 'Financial Reports', 'Nondiscrimination Policy', 'Academics', '5th Grade', '6th Grade', '7th Grade', '8th Grade', 'Associated Arts', 'Summer Reading >>', '5th Grade Reading List', '6th Grade Reading List', '7th Grade Reading List', '8th Grade Reading List', 'Parents', 'General Information', 'School Calendar >>', 'Download Calendar', 'PlusPortals', 'Before & After School Care', 'Forms >>', 'New Student Registration Packet', 'Free and Reduced Lunch', 'Student Handbook', 'School Uniform Order Form', 'School Supplies >>', '5th Grade', '6th Grade', '7th Grade', '8th Grade', 'Food Menu', 'PARCC', 'Inclement Weather Schedule', 'West Side Bus Routes', 'Athletics', 'Coach Contact Info', 'Athletics Schedule', 'Sports News', 'Sports Release', 'Physical Form', 'Student Athlete Contract', 'Student Athlete Grade Check', 'Committees', 'Parent Teacher Association >>', 'Contact Info', 'Agendas and Minutes', 'Governance Council >>', 'Contact Info', 'Agendas and Minutes', 'Foundation >>', 'Contact Info', 'Agendas and Minutes', 'Search', 'About', 'You are here:', 'Home', '/', 'About', 'About 21st Century', '21st Century is a charter middle school. We have been a school since 2000. We serve a diverse population of nearly 70 students per grade. All staff bring years of teaching experience into our classrooms, and many have worked together in other settings. We emphasize the core curriculum of Math, Science, Social Studies, and Language Arts, as well as learning experiences in the community, city, and state. Two Associated Arts courses are offered to each student every semester, including music and media programs.', 'History', '21st Century Public Academy was declared an official charter in 1999 by the Board of the Albuquerque Public Schools and State Department of Education. 40 6th grade students were permitted to enter the doors for the first time in September, 2000, making it officially the first charter middle school in Albuquerque, New Mexico. The school’s first 8th grade graduation was held in May, 2003.', 'The school was started by teachers who had worked together under a charter at Taylor Middle School: Art Silva, Math; Kitty Krivitzky, Science; Darlene Arias, Social Studies; Heather Sickenger, Language Arts. Donna Eldredge joined the team as a Special Ed teacher and principal.', '21st Century is still going strong to this day.', 'Mission', 'It is the mission of 21st Century Public Academy to continually search for positive learning experiences that enrich students and staff. Whenever possible, these lessons will take place in the arena in which they are practiced.', 'Vision', '21st Century Public Academy will provide experiences, situations, and opportunities for students to develop talents and to understand their role in the community. The body, mind, and spirit of each person will grow through lessons learned at school. Students will acquire a sense of personal responsibility, independence, and community interdependence.', 'School Hours', 'Regular School Hours:', '8:15-3:40 Monday, Tuesday, Thursday, Friday', '8:15-3:00 Wednesday', 'Students may not be dropped off prior to 8:00.', 'Recent News', '6th Grade OSI to the Petroglyphs', '(December 13, 2017)', 'Spelling Bee', '(December 8, 2017)', 'Science Bowl Competition', '(December 7, 2017)', 'Boys Basketball', '(November 21, 2017)', '5th Grade OSI to US Eagle Federal Credit Union', '(November 15, 2017)', 'New West Side Bus Routes for 21stCPA', '(November 3, 2017)', '21st Century Girl’s Basketball starts October 25', '(October 23, 2017)', '7th Grade OSI to El Rancho de las Golondrinas', '(October 11, 2017)', 'Girls Basketball Season', '(October 9, 2017)', 'Cross Country Photos', '(October 5, 2017)', '21st Century Public Academy – APS Charter Middle School', '4300 Cutler Ave NE', 'Albuquerque, NM 87110', 'Phone: (505)254-0280', 'Fax: (505)254-8507', 'Scroll to top'] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if Debug:\n",
    "    example_textlist = parsefile_by_tags(example_file)\n",
    "    print(\"Output of parsefile_by_tags:\\n\\n\", example_textlist, \"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dict_page(pagetext_list, keyslist):\n",
    "    \n",
    "    \"\"\"Filters webtext of a given .html page, which is parsed and in list format, to only those strings \n",
    "    within pagetext_list containing an element (word or words) of inputted keyslist. \n",
    "    Returns list filteredtext wherein each element has original case (not coerced to lower-case).\"\"\"\n",
    "    \n",
    "    filteredtext = [] # Initialize empty list to hold strings of page\n",
    "    \n",
    "    for string in pagetext_list:\n",
    "        lowercasestring = str(string).lower() # lower-case string...\n",
    "        dict_list = [key.lower() for key in list(keyslist)] # ...compared with lower-case element of keyslist\n",
    "        for key in dict_list:\n",
    "            if key in lowercasestring and key in lowercasestring.split(' '): # Check that the word is the whole word not part of another one\n",
    "                filteredtext.extend(string)\n",
    "\n",
    "    return filteredtext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of filter_keywords_page with keywords:\n",
      "\n",
      " ['21st Century is a charter middle school. We have been a school since 2000. We serve a diverse population of nearly 70 students per grade. All staff bring years of teaching experience into our classrooms, and many have worked together in other settings. We emphasize the core curriculum of Math, Science, Social Studies, and Language Arts, as well as learning experiences in the community, city, and state. Two Associated Arts courses are offered to each student every semester, including music and media programs.', 'Mission', 'It is the mission of 21st Century Public Academy to continually search for positive learning experiences that enrich students and staff. Whenever possible, these lessons will take place in the arena in which they are practiced.', 'Vision'] \n",
      "\n",
      "\n",
      "Output of filter_keywords_page with ideology words:\n",
      "\n",
      " ['School Uniform Order Form', 'School Uniform Order Form', '21st Century is a charter middle school. We have been a school since 2000. We serve a diverse population of nearly 70 students per grade. All staff bring years of teaching experience into our classrooms, and many have worked together in other settings. We emphasize the core curriculum of Math, Science, Social Studies, and Language Arts, as well as learning experiences in the community, city, and state. Two Associated Arts courses are offered to each student every semester, including music and media programs.', '21st Century is a charter middle school. We have been a school since 2000. We serve a diverse population of nearly 70 students per grade. All staff bring years of teaching experience into our classrooms, and many have worked together in other settings. We emphasize the core curriculum of Math, Science, Social Studies, and Language Arts, as well as learning experiences in the community, city, and state. Two Associated Arts courses are offered to each student every semester, including music and media programs.', '21st Century is a charter middle school. We have been a school since 2000. We serve a diverse population of nearly 70 students per grade. All staff bring years of teaching experience into our classrooms, and many have worked together in other settings. We emphasize the core curriculum of Math, Science, Social Studies, and Language Arts, as well as learning experiences in the community, city, and state. Two Associated Arts courses are offered to each student every semester, including music and media programs.', 'The school was started by teachers who had worked together under a charter at Taylor Middle School: Art Silva, Math; Kitty Krivitzky, Science; Darlene Arias, Social Studies; Heather Sickenger, Language Arts. Donna Eldredge joined the team as a Special Ed teacher and principal.', 'The school was started by teachers who had worked together under a charter at Taylor Middle School: Art Silva, Math; Kitty Krivitzky, Science; Darlene Arias, Social Studies; Heather Sickenger, Language Arts. Donna Eldredge joined the team as a Special Ed teacher and principal.', 'It is the mission of 21st Century Public Academy to continually search for positive learning experiences that enrich students and staff. Whenever possible, these lessons will take place in the arena in which they are practiced.', 'Girls Basketball Season'] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if Debug:\n",
    "    print(\"Output of filter_keywords_page with keywords:\\n\\n\", filter_dict_page(example_textlist, keys_dict), \"\\n\\n\")\n",
    "    \n",
    "    print(\"Output of filter_keywords_page with ideology words:\\n\\n\", filter_dict_page(example_textlist, ideol_dict), \"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_school(school_dict, school_name, school_address, school_URL, datalocation, parsed, numschools):\n",
    "    \n",
    "    \"\"\"This core function parses webtext for a given school, using helper functions to run analyses and then saving multiple outputs to school_dict:\n",
    "    full (partially cleaned) webtext, by parsing webtext of each .html file (removing inline tags, etc.) within school's folder, via parsefile_by_tags();\n",
    "    filtered webtext, by keeping only those parsed text elements containing a keyword in previously defined keywords list, via filter_keywords_page();\n",
    "    parsed webtext, having removed overlapping headers/footers common to multiple pages, via remove_overlaps();\n",
    "    all text associated with specific categories by filtering webtext according to keywords for \n",
    "    mission, curriculum, philosophy, history, and about/general self-description, via categorize_page(); and\n",
    "    contents of those individual pages best matching each of these categories, via find_best_categories.\"\"\"\n",
    "    \n",
    "    global itervar # This allows function to access global itervar counter\n",
    "    itervar+=1\n",
    "    \n",
    "    print(\"Parsing \" + str(school_name) + \", which is school #\" + str(itervar) + \" of \" + str(numschools) + \"...\")\n",
    "    \n",
    "    school_dict[\"webtext\"], school_dict[\"keywords_text\"], school_dict[\"ideology_text\"], school_dict[\"duplicate_flag\"], school_dict[\"parse_error_flag\"], school_dict[\"wget_fail_flag\"] = [], [], [], 0, 0, 0\n",
    "    \n",
    "    folder_name = re.sub(\" \",\"_\",(school_name+\" \"+school_address[-8:-6]))\n",
    "    school_dict[\"folder_name\"] = folder_name\n",
    "    \n",
    "    school_folder = datalocation + folder_name + \"/\"\n",
    "\n",
    "    # Check if folder exists. If not, exit function\n",
    "    if not (os.path.exists(school_folder) or os.path.exists(school_folder.lower()) or os.path.exists(school_folder.upper())):\n",
    "        print(\"!! NO DIRECTORY FOUND matching \" + str(school_folder) + \".\\n  Aborting parsing function...\\n\\n\")\n",
    "        school_dict['wget_fail_flag'] = 1\n",
    "        return\n",
    "    \n",
    "    if school_URL not in parsed: #check if this URL has already been parsed. If so, skip this school to avoid duplication bias\n",
    "        parsed.append(school_URL)\n",
    "        \n",
    "        try:\n",
    "            file_count = 0 # initialize count of files parsed\n",
    "            \n",
    "            # Parse file only if it contains HTML. This is easy: use the \"*.html\" wildcard pattern--\n",
    "            # also wget gave the \".html\" file extension to appropriate files when downloading (`--adjust-extension` option)\n",
    "            # Less efficient ways to check if files contain HTML (e.g., for data not downloaded by wget):\n",
    "            # if bool(BeautifulSoup(open(fname), bsparser).find())==True: # if file.endswith(\".html\"):\n",
    "            # Another way to do this, maybe faster but broken: files_iter = iglob(school_folder + \"**/*.html\", recursive=True)\n",
    "            \n",
    "            file_list = list_files(school_folder, \".html\")\n",
    "            \n",
    "            if file_list==(None or school_folder) or not file_list:\n",
    "                print(\"ERROR! File gathering function broken!\\n  Aborting parser for \" + str(school_name) + \"...\")\n",
    "                return\n",
    "            \n",
    "            elif file_list==(\"\" or []):\n",
    "                print(\"  No .html files found.\\n  Aborting parser for \" + str(school_name) + \"...\")\n",
    "                return\n",
    "            \n",
    "            for file in file_list:\n",
    "                                    \n",
    "                file_count+=1 # add to count of parsed files\n",
    "                if Debug:\n",
    "                    print(\"    Parsing HTML in \" + str(file) + \"...\")\n",
    "                    \n",
    "                try:                    \n",
    "                    parsed_pagetext = parsefile_by_tags(file) # Parse page text (filter too?)\n",
    "                    if Debug:\n",
    "                        print(\"      Successfully parsed page text by tags!\")\n",
    "                        \n",
    "                    school_dict[\"webtext\"].extend(parsed_pagetext) # Add new parsed text to long list\n",
    "\n",
    "                    school_dict[\"keywords_text\"].extend(filter_dict_page(parsed_pagetext, keys_dict)) # Filter parsed file using keywords list\n",
    "                    school_dict[\"ideology_text\"].extend(filter_dict_page(parsed_pagetext, ideol_dict)) # Filter parsed file using keywords list\n",
    "\n",
    "                    if Debug:\n",
    "                        print(\"      Successfully parsed and filtered file \" + str(file) + \"...\")\n",
    "                        \n",
    "                    file_count+=1\n",
    "                        \n",
    "                    continue\n",
    "\n",
    "                except Exception as e:\n",
    "                    if Debug:\n",
    "                        print(\"      ERROR! Failed to parse file...\")\n",
    "                        print(\"      \",e)\n",
    "                        continue\n",
    "                    else:\n",
    "                        continue\n",
    "            \n",
    "            if Debug:\n",
    "                print(\"  Parsed page text for \" + str(file_count-1) + \" .html file(s) belonging to \" + str(school_name) + \"...\")\n",
    "            \n",
    "            print(\"SUCCESS! Parsed and categorized website text for \" + str(school_name) + \"...\\n\\n\")\n",
    "            return\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"    ERROR! Failed to parse & categorize webtext of \" + str(school_name))\n",
    "            print(\"    \",e)\n",
    "            school_dict[\"parse_error_flag\"] = 1\n",
    "    \n",
    "    else:\n",
    "        print(\"DUPLICATE URL DETECTED. Skipping \" + str(school_name) + \"...\\n\\n\")\n",
    "        school_dict[\"duplicate_flag\"] = 1\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Preparing data to be parsed\n",
    "\n",
    "itervar = 0 # initialize iterator that counts number of schools already parsed\n",
    "parsed = [] # initialize list of URLs that have already been parsed\n",
    "dicts_list = [] # initialize list of dictionaries to hold school data\n",
    "\n",
    "# If input_file was defined by user input in beginning of script, use that to load list of dictionaries. We'll add to it!\n",
    "if usefile and not dicts_list:\n",
    "    dicts_list = load_file(input_file)\n",
    "    data_loc = full_schooldata # If loading data, assume we're running on full charter population\n",
    "\n",
    "else:\n",
    "    # set charter school data file and corresponding varnames:\n",
    "    \n",
    "    data_loc = full_schooldata # Run at scale using URL list of full charter population\n",
    "    # data_loc = micro_sample13 # This seems nice for debugging--except directories don't match because different data source\n",
    "        \n",
    "    # Create dict list from CSV on file, with one dict per school\n",
    "    with open(data_loc, 'r', encoding = 'Latin1') as csvfile: # open data file\n",
    "        reader = csv.DictReader(csvfile) # create a reader\n",
    "        for row in reader: # loop through rows\n",
    "            dicts_list.append(row) # append each row to the list\n",
    "        \n",
    "URL_var,NAME_var,ADDR_var = get_vars(data_loc) # get varnames depending on data source\n",
    "        \n",
    "# Note on data structures: each row, dicts_list[i] is a dictionary with keys as column name and value as info.\n",
    "# This will be translated into pandas data frame once (rather messy) website text is parsed into consistent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing 21st Century Charter Sch of Gary, which is school #1 of 6752...\n",
      "    Parsing HTML in /home/jovyan/work/wget/parll_wget/21st_Century_Charter_Sch_of_Gary_IN/www.21cchartergary.org/default.tmp.html...\n",
      "      Successfully parsed page text by tags!\n",
      "      Successfully parsed and filtered file /home/jovyan/work/wget/parll_wget/21st_Century_Charter_Sch_of_Gary_IN/www.21cchartergary.org/default.tmp.html...\n",
      "  Parsed page text for 1 .html file(s) belonging to 21st Century Charter Sch of Gary...\n",
      "SUCCESS! Parsed and categorized website text for 21st Century Charter Sch of Gary...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ### Run parsing algorithm on schools (requires access to webcrawl output)\n",
    "\n",
    "test_dicts = dicts_list[:1] # Limit number of schools to analyze, in order to refine methods\n",
    "\n",
    "if Debug:\n",
    "    for school in test_dicts:\n",
    "        parse_school(school, school[NAME_var], school[ADDR_var], school[URL_var], wget_dataloc, parsed, len(dicts_list))\n",
    "        \n",
    "else:\n",
    "    for school in dicts_list:\n",
    "        parse_school(school, school[NAME_var], school[ADDR_var], school[URL_var], wget_dataloc, parsed, len(dicts_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('SEARCH', '21st Century Charter Sch of Gary 556 Washington St, Gary, IN 46402'), ('MANUAL_URL', ''), ('ADDRESS', '556 Washington St, Gary, IN 46402'), ('TRUE_URL', 'http://www.21cchartergary.org/'), ('CONFIRMED_CLOSED', '0'), ('SCH_NAME', '21st Century Charter Sch of Gary'), ('OLD_URL', 'http://www.21ccharter.org/'), ('NCESSCH', '1.80E+11'), ('STABR', 'IN'), ('webtext', ['Home', 'About Us', 'About Us', 'Principal Welcome', 'Teachers & Staff', 'School Board', 'Board Minutes', 'Careers', 'News', 'Our Approach', 'Academics', 'Free College', 'Technology', 'Student Life', 'Our Graduates', 'Enroll Your Child', 'Current Parents', 'PowerSchool', 'School Calendar', 'Meal Menus', 'Guidance Corner', 'Odyssey Login', 'PAWSS', 'Student Portal', 'Facebook', 'Twitter', 'Tweets by @twitter', 'dual-diagnosis-help.com', 'Latest News', 'NWI TIMES: U.S. Education Secretary Betsy DeVos puts Gary on the map', '2017 Tours to various Colleges for all in grades 7 to 12. Plan to Attend: Click here!!', 'TEEN VOGUE: How This 18-Year-Old Graduated College Before High School', '#Gary2College: Where Our Graduates Go', 'Proudly Sponsored by ', 'GEO Foundation', 'Contact Us', 'Careers', 'Latest News', 'Enroll Now', 'Free College', 'twitter', 'facebook', 'youtube', 'ELEMENTARY: 556 WASHINGTON ST.     |     GARY, IN 46402     |     PHONE: 219-886-9339     |     FAX: 219-886-0869    |     E-MAIL: info@geofoundation.org  ', 'SECONDARY: 724 WASHINGTON ST.     |     GARY, IN 46402     |     PHONE: 219-888-7130     |    FAX: 219-880-1771     |     E-MAIL: info@geofoundation.org', 'GEO Foundation © 2015    |   ', 'Privacy Policy', '   |   ', 'Nondiscrimination Policy', '   |   ', 'Employee Portal', 'Scroll to Top', 'JavaScript is currently disabled.', 'Please enable it for a better experience of ', 'Jumi', '.']), ('keywords_text', ['Our Approach']), ('ideology_text', []), ('duplicate_flag', 0), ('parse_error_flag', 0), ('wget_fail_flag', 0), ('folder_name', '21st_Century_Charter_Sch_of_Gary_IN')])\n"
     ]
    }
   ],
   "source": [
    "# Check out results:\n",
    "if Debug:\n",
    "    print(test_dicts[0])\n",
    "else:\n",
    "    print(dicts_list[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save output:\n",
    "if Debug:\n",
    "    dictfile = \"testing_dicts_\" + str(datetime.today())\n",
    "    save_to_file(test_dicts, save_dir+dictfile, \"JSON\")\n",
    "else:\n",
    "    dictfile = \"school_dicts_\" + str(datetime.today())\n",
    "    save_to_file(dicts_list, save_dir+dictfile, \"JSON\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
