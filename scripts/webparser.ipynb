{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: UTF-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing & Categorizing HTML from `wget` run!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import os, re # for navigating file trees and working with strings\n",
    "import csv # for reading in CSV files\n",
    "from glob import glob # for finding files within nested folders\n",
    "import json, pickle # For saving a loading dictionaries, etc. from file with JSON and pickle formats\n",
    "from datetime import datetime # For timestamping files\n",
    "from nltk.stem.porter import PorterStemmer # an approximate method of stemming words\n",
    "stemmer = PorterStemmer()\n",
    "from nltk import word_tokenize, sent_tokenize # widely used text tokenizer\n",
    "import urllib, urllib.request # for testing pages\n",
    "\n",
    "# Import parser\n",
    "from bs4 import BeautifulSoup # BS reads and parses even poorly/unreliably coded HTML \n",
    "from bs4.element import Comment # helps with detecting inline/junk tags when parsing with BS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inline_tags = [\"b\", \"big\", \"i\", \"small\", \"tt\", \"abbr\", \"acronym\", \"cite\", \"dfn\",\n",
    "               \"em\", \"kbd\", \"strong\", \"samp\", \"var\", \"bdo\", \"map\", \"object\", \"q\",\n",
    "               \"span\", \"sub\", \"sup\"] # this list helps with eliminating junk tags when parsing HTML\n",
    "\n",
    "Debug = True # Set to \"True\" for extra progress reports while algorithms run\n",
    "notebook = True # Use different file paths depending on whether files are being accessed from shell (False) or within a Jupyter notebook (True)\n",
    "usefile = False # Set to \"True\" if loading from file a dicts_list to add to\n",
    "\n",
    "# Set parser for BeautifulSoup to use depending on whether code is running in notebook or not \n",
    "# (notebooks don't have faster lxml parser installed)\n",
    "if notebook:\n",
    "    bsparser = \"html.parser\"\n",
    "else:\n",
    "    import lxml # for fast HTML parsing with BS\n",
    "    bsparser = \"lxml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Set directories\n",
    "\n",
    "if notebook:\n",
    "    dir_prefix = \"/home/jovyan/work/\"\n",
    "else:\n",
    "    dir_prefix = \"/vol_b/data/\"\n",
    "    \n",
    "wget_dataloc = dir_prefix + \"wget/parll_wget/\" #data location for schools downloaded with wget in parallel\n",
    "micro_sample13 = dir_prefix + \"Charter-school-identities/data/micro-sample13_coded.csv\" #data location for random micro-sample of 300 US charter schools\n",
    "full_schooldata = dir_prefix + \"Charter-school-identities/data/charter_URLs_2014.csv\" #data location for 2014 population of US charter schools\n",
    "save_dir = dir_prefix + \"Charter-school-identities/data/\"\n",
    "\n",
    "example_page = \"https://westlakecharter.com/about/\"\n",
    "example_schoolname = \"TWENTY-FIRST_CENTURY_NM\"\n",
    "example_folder = wget_dataloc + \"TWENTY-FIRST_CENTURY_NM/\"\n",
    "example_file = dir_prefix + \"wget/example_file.html\" #example_folder + \"21stcenturypa.com/wp/default?page_id=27.tmp.html\"\n",
    "\n",
    "print(\"\\nWould you like to load a list of dictionaries from file?\")\n",
    "if usefile:\n",
    "    input_file = # Ask user what file to use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Set parsing keywords\n",
    "\n",
    "keywords = ['values', 'academics', 'skills', 'purpose',\n",
    "                       'direction', 'mission', 'vision', 'vision', 'mission', 'our purpose',\n",
    "                       'our ideals', 'ideals', 'our cause', 'curriculum','curricular',\n",
    "                       'method', 'pedagogy', 'pedagogical', 'approach', 'model', 'system',\n",
    "                       'structure','philosophy', 'philosophical', 'beliefs', 'believe',\n",
    "                       'principles', 'creed', 'credo', 'values','moral', 'history', 'our story',\n",
    "                       'the story', 'school story', 'background', 'founding', 'founded',\n",
    "                       'established','establishment', 'our school began', 'we began',\n",
    "                       'doors opened', 'school opened', 'about us', 'our school', 'who we are',\n",
    "                       'our identity', 'profile', 'highlights']\n",
    "\n",
    "mission_keywords = ['mission','vision', 'vision:', 'mission:', 'our purpose', 'our ideals', 'ideals:', 'our cause', 'cause:', 'goals', 'objective']\n",
    "curriculum_keywords = ['curriculum', 'curricular', 'program', 'method', 'pedagogy', 'pedagogical', 'approach', 'model', 'system', 'structure']\n",
    "philosophy_keywords = ['philosophy', 'philosophical', 'beliefs', 'believe', 'principles', 'creed', 'credo', 'value',  'moral']\n",
    "history_keywords = ['history', 'story','our story', 'the story', 'school story', 'background', 'founding', 'founded', 'established', 'establishment', 'our school began', 'we began', 'doors opened', 'school opened']\n",
    "about_keywords =  ['about us', 'our school', 'who we are', 'overview', 'general information', 'our identity', 'profile', 'highlights']\n",
    "\n",
    "mission_keywords = set(stemmer.stem(word) for word in mission_keywords)\n",
    "curriculum_keywords = set(stemmer.stem(word) for word in curriculum_keywords)\n",
    "philosophy_keywords = set(stemmer.stem(word) for word in philosophy_keywords)\n",
    "history_keywords = set(stemmer.stem(word) for word in history_keywords)\n",
    "about_keywords =  set(stemmer.stem(word) for word in about_keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Define (non-parsing) helper functions\n",
    "\n",
    "def get_vars(data):\n",
    "    \"\"\"Defines variable names based on the data source called.\"\"\"\n",
    "    \n",
    "    if data==full_schooldata:\n",
    "        URL_variable = \"TRUE_URL\"\n",
    "        NAME_variable = \"SCH_NAME\"\n",
    "        ADDR_variable = \"ADDRESS\"\n",
    "    \n",
    "    elif data==micro_sample13:\n",
    "        URL_variable = \"URL\"\n",
    "        NAME_variable = \"SCHNAM\"\n",
    "        ADDR_variable = \"ADDRESS\"\n",
    "    \n",
    "    else:\n",
    "        try:\n",
    "            print(\"Error processing variables from data file \" + str(data) + \"!\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"ERROR: No data source established!\\n\")\n",
    "    \n",
    "    return(URL_variable,NAME_variable,ADDR_variable)\n",
    "\n",
    "\n",
    "def tag_visible(element):\n",
    "    \"\"\"Returns false if a web element has a non-visible tag, \n",
    "    i.e. one site visitors wouldn't actually read--and thus one we don't want to parse\"\"\"\n",
    "    \n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def webtext_from_files(datalocation):\n",
    "    \"\"\"Concatenate and return a single string from all webtext (with .txt format) in datalocation\"\"\"\n",
    "    \n",
    "    string = \"\"\n",
    "    for root, dirs, files in os.walk(datalocation):\n",
    "        for file in files:\n",
    "            if file.endswith(\".txt\"):\n",
    "                fileloc = open(datalocation+file, \"r\")\n",
    "                string = string + (fileloc.read())\n",
    "    return string\n",
    "\n",
    "\n",
    "def remove_spaces(file_path):\n",
    "    \"\"\"Remove spaces from text file at file_path\"\"\"\n",
    "    \n",
    "    words = [x for x in open(file_path).read().split() if x != \"\"]\n",
    "    text = \"\"\n",
    "    for word in words:\n",
    "        text += word + \" \"\n",
    "    return text\n",
    "\n",
    "\n",
    "def save_to_file(dicts_list, file, mode):\n",
    "    \"\"\"Saves dicts_list to file using JSON or pickle format (whichever was specified).\"\"\"\n",
    "    \n",
    "    file = str(file)\n",
    "    \n",
    "    try:\n",
    "        if mode==\"JSON\":\n",
    "            if not file.endswith(\".json\"):\n",
    "                file += \".json\"\n",
    "            with open(file, 'wb') as outfile:\n",
    "                json.dump(dicts_list, outfile)\n",
    "            #pickle.dump(dicts_list, outfile)\n",
    "                print(dicts_list + \" successfully saved to \" + file + \"in JSON format!\\n\")\n",
    "\n",
    "        elif mode==\"pickle\":\n",
    "            if not file.endswith(\".pickle\"):\n",
    "                file += \".pickle\"\n",
    "            with open(file, 'wb') as outfile:\n",
    "                pickle.dump(dicts_list, outfile)\n",
    "                print(dicts_list + \" successfully saved to \" + file + \" in pickle format!\\n\")\n",
    "\n",
    "        else:\n",
    "            print(\"ERROR! Save failed due to improper arguments. These are: file, object to be saved, and file format to save in.\\n\\\n",
    "                  Specify either 'JSON' or 'pickle' as third argument ('mode' or file format) when calling this function.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "\n",
    "def load_file(file):\n",
    "    \"\"\"Loads dicts_list (or whatever) from file, using either JSON or pickle format. \n",
    "    The created object should be assigned when called.\"\"\"\n",
    "    \n",
    "    file = str(file)\n",
    "    \n",
    "    with open(file,'rb') as infile:\n",
    "        if file.endswith(\".json\"):\n",
    "            var = json.load(infile)\n",
    "        if file.endswith(\".pickle\"):\n",
    "            var = pickle.load(infile)\n",
    "        print(file + \" successfully loaded!\\n\")\n",
    "    return var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'Contact Us: 2680 Mabry Dr. 95835 (916) 567-5760 | admin@westlakecharter.com', 'Staff Login', 'About', 'Administration & Support Staff  Employment Opportunities  Business Services  Admission & Enrollment Information  Supply Donations  Hot Lunch Payments  Hot Lunch Menu', 'Board', 'Board Policies  Board Committees  Board Documents', 'WCS', 'Infinite Campus Login  School Dismissal Manager  Ways to Westlake', 'Teachers  BASE  WAVE', 'Meetings  Contact Us  Volunteer Opportunities  Volunteer Hours  Log Volunteer Hours  Spirit Store', 'Calendars', '17/18 School Calendar  18/19 School Calendar', 'About', 'About  Aimee Wells  2013-09-18T18:36:35+00:00', 'About Westlake Charter Schools  Key School Features', 'International Focus  Thematic Curriculum  Artistic Development  Foreign Language Instruction  School-Wide Enrichment Model', 'Core Values', 'Respect  Excellence  Responsibility  Reflective  Global Perspective  Stewardship  Perseverance  Inquisitive  Joyful Learning  Gratitude', 'Calendars, Schedules, Handbooks and More', 'Family Handbook  2017/18 School Calendar  2017/18 Bell Schedule  WCS Charter  Strategic Plan', 'Westlake Charter School is a K-8th grade public elementary school created by parents and educators in Natomas. We opened our doors in 2005 and continue to grow serving more and more students each year. WCS’s primary mission is to demonstrate what is possible when school and community collaborate to create inspiring adults with the academic and social-emotional readiness to lead as Global Citizens.  Westlake Charter School students are EXPLORERS! Our curriculum focuses on diversity and appreciation of different cultures, while promoting academic excellence and foreign language acquisition. We offer various specialty classes to all of our students including Art, Physical Education, and Spanish. Our middle school program focuses on Math, Science and Technology and is executed through the use of technology. Westlake Charter School has small class sizes of approximately 22-24 students in K-3rd grade and 29 students in 4th-8th grade.  First time visitors to Westlake Charter School often remark, “What a warm and inviting school!” Creating a school that is caring and open is absolutely critical in working successfully with our children and families. Students who feel safe, secure, and appreciated gain a love of learning and will be successful scholars.  Westlake Charter School’s professional staff is relentless in seeking and trying research-based best practices that engage every student. Our lessons are hands-on and differentiated to meet the diverse needs of all students. Our teachers display a never-ending commitment to improving their own expertise. Furthermore, we would not be as successful without the support and involvement of our parents. Our parent group is outstanding in helping us achieve our goals by volunteering their time in class, fundraising for our unique programs, and providing endless words of encouragement and support. Our school team is second to none!', 'Recent', 'Westlake Weekly – December 15, 2017  December 15th, 2017', 'Westlake Weekly – December 8, 2017  December 8th, 2017', 'Westlake Weekly – December 1, 2017  December 1st, 2017', 'Westlake Weekly – November 17, 2017  November 17th, 2017', 'Westlake Weekly – November 9, 2017  November 9th, 2017', 'Westlake Weekly – November 3, 2017  November 3rd, 2017', 'Contact Info', '2680 Mabry Dr. 95835  Phone: (916) 567-5760  Fax: (916) 567-5769  Email: admin@westlakecharter.com', 'Copyright 2015 Westlake Charter | All Rights Reserved | Contact Us', ''] \n",
      "\n",
      " ['Contact Us: 2680 Mabry Dr. 95835 (916) 567-5760', '|', 'admin@westlakecharter.com', 'Staff Login', 'About', 'Administration & Support Staff', 'Employment Opportunities', 'Business Services', 'Admission & Enrollment Information', 'Supply Donations', 'Hot Lunch Payments', 'Hot Lunch Menu', 'Board', 'Board Policies', 'Board Committees', 'Board Documents', 'WCS', 'Infinite Campus Login', 'School Dismissal Manager', 'Ways to Westlake', 'Teachers', 'BASE', 'WAVE', 'Meetings', 'Contact Us', 'Volunteer Opportunities', 'Volunteer Hours', 'Log Volunteer Hours', 'Spirit Store', 'Calendars', '17/18 School Calendar', '18/19 School Calendar', 'About', 'About', 'Aimee Wells', '2013-09-18T18:36:35+00:00', 'About Westlake Charter Schools', 'Key School Features', 'International Focus', 'Thematic Curriculum', 'Artistic Development', 'Foreign Language Instruction', 'School-Wide Enrichment Model', 'Core Values', 'Respect', 'Excellence', 'Responsibility', 'Reflective', 'Global Perspective', 'Stewardship', 'Perseverance', 'Inquisitive', 'Joyful Learning', 'Gratitude', 'Calendars, Schedules, Handbooks and More', 'Family Handbook', '2017/18 School Calendar', '2017/18 Bell Schedule', 'WCS Charter', 'Strategic Plan', 'Westlake Charter School is a K-8th grade public elementary school created by parents and educators in Natomas. We opened our doors in 2005 and continue to grow serving more and more students each year. WCS’s primary mission is to demonstrate what is possible when school and community collaborate to create inspiring adults with the academic and social-emotional readiness to lead as Global Citizens.', 'Westlake Charter School students are EXPLORERS! Our curriculum focuses on diversity and appreciation of different cultures, while promoting academic excellence and foreign language acquisition. We offer various specialty classes to all of our students including Art, Physical Education, and Spanish. Our middle school program focuses on Math, Science and Technology and is executed through the use of technology. Westlake Charter School has small class sizes of approximately 22-24 students in K-3rd grade and 29 students in 4th-8th grade.', 'First time visitors to Westlake Charter School often remark, “What a warm and inviting school!” Creating a school that is caring and open is absolutely critical in working successfully with our children and families. Students who feel safe, secure, and appreciated gain a love of learning and will be successful scholars.', 'Westlake Charter School’s professional staff is relentless in seeking and trying research-based best practices that engage every student. Our lessons are hands-on and differentiated to meet the diverse needs of all students. Our teachers display a never-ending commitment to improving their own expertise. Furthermore, we would not be as successful without the support and involvement of our parents. Our parent group is outstanding in helping us achieve our goals by volunteering their time in class, fundraising for our unique programs, and providing endless words of encouragement and support. Our school team is second to none!', 'Recent', 'Westlake Weekly – December 15, 2017', 'December 15th, 2017', 'Westlake Weekly – December 8, 2017', 'December 8th, 2017', 'Westlake Weekly – December 1, 2017', 'December 1st, 2017', 'Westlake Weekly – November 17, 2017', 'November 17th, 2017', 'Westlake Weekly – November 9, 2017', 'November 9th, 2017', 'Westlake Weekly – November 3, 2017', 'November 3rd, 2017', 'Contact Info', '2680 Mabry Dr. 95835', 'Phone: (916) 567-5760', 'Fax: (916) 567-5769', 'Email: ', 'admin@westlakecharter.com', 'Copyright 2015 Westlake Charter | All Rights Reserved | ', 'Contact Us']\n"
     ]
    }
   ],
   "source": [
    "# ### Compare parsing by newlines vs. by HTML tags\n",
    "\n",
    "def parseurl_by_newlines(urlstring):\n",
    "    \"\"\"Uses BS to parse HTML from a given URL and looks for three newlines to separate chunks of text.\"\"\"\n",
    "    \n",
    "    # Read HTML from a given url:\n",
    "    with urllib.request.urlopen(urlstring) as url:\n",
    "        s = url.read()\n",
    "    \n",
    "    # Parse raw text from website body:\n",
    "    soup = BeautifulSoup(s, bsparser)\n",
    "    texts = soup.findAll(text=True)\n",
    "    visible_texts = filter(tag_visible, texts)  \n",
    "    webtext = u\" \".join(t.strip() for t in visible_texts)\n",
    "    \n",
    "    return re.split(r'\\s{3,}', webtext)\n",
    "\n",
    "\n",
    "def parseurl_by_tags(urlstring):\n",
    "    \"\"\"Cleans HTML by removing inline tags, ripping out non-visible tags, \n",
    "    replacing paragraph tags with a random string, and finally using this to separate HTML into chunks.\n",
    "    Reads in HTML from the web using a given website address, urlstring.\"\"\"\n",
    "    \n",
    "    with urllib.request.urlopen(urlstring) as url:\n",
    "        HTML_page = url.read()\n",
    "\n",
    "    random_string = \"\".join(map(chr, os.urandom(75))) # Create random string for tag delimiter\n",
    "    soup = BeautifulSoup(HTML_page, bsparser)\n",
    "    \n",
    "    [s.extract() for s in soup(['style', 'script', 'head', 'title', 'meta', '[document]'])] # Remove non-visible tags\n",
    "    for it in inline_tags:\n",
    "        [s.extract() for s in soup(\"</\" + it + \">\")] # Remove inline tags\n",
    "    \n",
    "    visible_text = soup.getText(random_string).replace(\"\\n\", \"\") # Replace \"p\" tags with random string, eliminate newlines\n",
    "    visible_text = list(elem.replace(\"\\t\",\"\") for elem in visible_text.split(random_string)) # Split text into list using random string while eliminating tabs\n",
    "    visible_text = list(filter(lambda vt: vt.split() != [], visible_text)) # Eliminate empty elements\n",
    "    # Consider joining list elements together with newline in between by prepending with: \"\\n\".join\n",
    "    \n",
    "    return(visible_text)\n",
    "\n",
    "\n",
    "# Text chunking accuracy of parsing by tags is superior to parsing by newlines:\n",
    "# Compare each of these with the browser-displayed content of example_page:\n",
    "if Debug:\n",
    "    print(parseurl_by_newlines(example_page),\"\\n\\n\",parseurl_by_tags(example_page))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Define parsing helper functions\n",
    "\n",
    "def parsefile_by_tags(HTML_file):\n",
    "    \n",
    "    \"\"\"Cleans HTML by removing inline tags, ripping out non-visible tags, \n",
    "    replacing paragraph tags with a random string, and finally using this to separate HTML into chunks.\n",
    "    Reads in HTML from storage using a given filename, HTML_file.\"\"\"\n",
    "\n",
    "    random_string = \"\".join(map(chr, os.urandom(75))) # Create random string for tag delimiter\n",
    "    soup = BeautifulSoup(open(HTML_file), bsparser)\n",
    "    \n",
    "    [s.extract() for s in soup(['style', 'script', 'head', 'title', 'meta', '[document]'])] # Remove non-visible tags\n",
    "    for it in inline_tags:\n",
    "        [s.extract() for s in soup(\"</\" + it + \">\")] # Remove inline tags\n",
    "    \n",
    "    visible_text = soup.getText(random_string).replace(\"\\n\", \"\") # Replace \"p\" tags with random string, eliminate newlines\n",
    "    visible_text = list(elem.replace(\"\\t\",\"\") for elem in visible_text.split(random_string)) # Split text into list using random string while eliminating tabs\n",
    "    visible_text = list(filter(lambda vt: vt.split() != [], visible_text)) # Eliminate empty elements\n",
    "    # Consider joining list elements together with newline in between by prepending with: \"\\n\".join\n",
    "\n",
    "    return(visible_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of parsefile_by_tags:\n",
      "\n",
      " ['About', 'Administration', 'Admissions', 'News', 'Charter School Information', 'Location', 'Frequently Asked Questions', 'Photos/Videos', 'School Facebook Page', 'Financial Reports', 'Nondiscrimination Policy', 'Academics', '5th Grade', '6th Grade', '7th Grade', '8th Grade', 'Associated Arts', 'Summer Reading >>', '5th Grade Reading List', '6th Grade Reading List', '7th Grade Reading List', '8th Grade Reading List', 'Parents', 'General Information', 'School Calendar >>', 'Download Calendar', 'PlusPortals', 'Before & After School Care', 'Forms >>', 'New Student Registration Packet', 'Free and Reduced Lunch', 'Student Handbook', 'School Uniform Order Form', 'School Supplies >>', '5th Grade', '6th Grade', '7th Grade', '8th Grade', 'Food Menu', 'PARCC', 'Inclement Weather Schedule', 'West Side Bus Routes', 'Athletics', 'Coach Contact Info', 'Athletics Schedule', 'Sports News', 'Sports Release', 'Physical Form', 'Student Athlete Contract', 'Student Athlete Grade Check', 'Committees', 'Parent Teacher Association >>', 'Contact Info', 'Agendas and Minutes', 'Governance Council >>', 'Contact Info', 'Agendas and Minutes', 'Foundation >>', 'Contact Info', 'Agendas and Minutes', 'Search', 'About', 'You are here:', 'Home', '/', 'About', 'About 21st Century', '21st Century is a charter middle school. We have been a school since 2000. We serve a diverse population of nearly 70 students per grade. All staff bring years of teaching experience into our classrooms, and many have worked together in other settings. We emphasize the core curriculum of Math, Science, Social Studies, and Language Arts, as well as learning experiences in the community, city, and state. Two Associated Arts courses are offered to each student every semester, including music and media programs.', 'History', '21st Century Public Academy was declared an official charter in 1999 by the Board of the Albuquerque Public Schools and State Department of Education. 40 6th grade students were permitted to enter the doors for the first time in September, 2000, making it officially the first charter middle school in Albuquerque, New Mexico. The school’s first 8th grade graduation was held in May, 2003.', 'The school was started by teachers who had worked together under a charter at Taylor Middle School: Art Silva, Math; Kitty Krivitzky, Science; Darlene Arias, Social Studies; Heather Sickenger, Language Arts. Donna Eldredge joined the team as a Special Ed teacher and principal.', '21st Century is still going strong to this day.', 'Mission', 'It is the mission of 21st Century Public Academy to continually search for positive learning experiences that enrich students and staff. Whenever possible, these lessons will take place in the arena in which they are practiced.', 'Vision', '21st Century Public Academy will provide experiences, situations, and opportunities for students to develop talents and to understand their role in the community. The body, mind, and spirit of each person will grow through lessons learned at school. Students will acquire a sense of personal responsibility, independence, and community interdependence.', 'School Hours', 'Regular School Hours:', '8:15-3:40 Monday, Tuesday, Thursday, Friday', '8:15-3:00 Wednesday', 'Students may not be dropped off prior to 8:00.', 'Recent News', '6th Grade OSI to the Petroglyphs', '(December 13, 2017)', 'Spelling Bee', '(December 8, 2017)', 'Science Bowl Competition', '(December 7, 2017)', 'Boys Basketball', '(November 21, 2017)', '5th Grade OSI to US Eagle Federal Credit Union', '(November 15, 2017)', 'New West Side Bus Routes for 21stCPA', '(November 3, 2017)', '21st Century Girl’s Basketball starts October 25', '(October 23, 2017)', '7th Grade OSI to El Rancho de las Golondrinas', '(October 11, 2017)', 'Girls Basketball Season', '(October 9, 2017)', 'Cross Country Photos', '(October 5, 2017)', '21st Century Public Academy – APS Charter Middle School', '4300 Cutler Ave NE', 'Albuquerque, NM 87110', 'Phone: (505)254-0280', 'Fax: (505)254-8507', 'Scroll to top'] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if Debug:\n",
    "    example_textlist = parsefile_by_tags(example_file)\n",
    "    print(\"Output of parsefile_by_tags:\\n\\n\", example_textlist, \"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_keywords_page(pagetext_list):\n",
    "    \n",
    "    \"\"\"Filters webtext of a given .html page, which is parsed and in list format, to only those strings \n",
    "    within pagetext_list containing an element (word or words) of a previously defined list of meaningful keywords.\"\"\"\n",
    "    \n",
    "    validcharacters = [' ', '.', '?']\n",
    "    filteredtext = []  \n",
    "    \n",
    "    for string in pagetext_list:\n",
    "        lowercasestring = string.lower()\n",
    "        for key in keywords:\n",
    "            if key in lowercasestring:\n",
    "                if key in lowercasestring.split(' '): #check that the word is the whole word not part of another one\n",
    "                    filteredtext.extend([string.lower()])\n",
    "\n",
    "    filteredtext = list(set(filteredtext))\n",
    "    finaltext = []\n",
    "    for x in filteredtext:\n",
    "        finaltext.append(x.replace('\\xa0', \" \")) # Clean up any remaining (non-readable) unicode\n",
    "    return finaltext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filter_page' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-6d8b72ff8fb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mDebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Output of filter_keywords_page:\\n\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_textlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'filter_page' is not defined"
     ]
    }
   ],
   "source": [
    "if Debug:\n",
    "    print(\"Output of filter_keywords_page:\\n\\n\", filter_keywords_page(example_textlist), \"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_page(pagetext_list): \n",
    "    \n",
    "    \"\"\"Takes in a list of all the relevant (filtered) text from a given webpage. \n",
    "    Categorizes each block of text by scoring based on keyword count, using already-defined lists \n",
    "    of keywords per category--mission, philosophy, curriculum, history, and \"about\"/general self-description.\"\"\"\n",
    "    \n",
    "    mission_list = []\n",
    "    curriculum_list = []\n",
    "    philosophy_list = []\n",
    "    history_list = []\n",
    "    about_list = []\n",
    "    \n",
    "    for string in pagetext_list:\n",
    "        mission_score, curriculum_score, philosophy_score, history_score, about_score = 0, 0, 0, 0, 0\n",
    "        for word in mission_keywords:\n",
    "            mission_score+=string.count(word)\n",
    "            if 'mission' in string.lower():\n",
    "                mission_score = 2\n",
    "                \n",
    "        for word in curriculum_keywords:\n",
    "            curriculum_score+=string.count(word)\n",
    "            if 'curriculum' in string.lower():\n",
    "                curriculum_score = 2\n",
    "                \n",
    "        for word in philosophy_keywords:\n",
    "            philosophy_score+=string.count(word)\n",
    "            if 'philosophy' in string.lower() or 'value' in string.lower():\n",
    "                philosophy_score = 2\n",
    "        \n",
    "        for word in history_keywords:\n",
    "            history_score+=string.count(word)\n",
    "            if 'history' in string.lower():\n",
    "                history_score = 2\n",
    "        \n",
    "        for word in about_keywords:\n",
    "            about_score+=string.count(word)\n",
    "            if 'about us' in string.lower() or \"about-us\" in string.lower():\n",
    "                about_score = 2\n",
    "        \n",
    "        if mission_score>=2:\n",
    "            mission_list.append(string)\n",
    "        if curriculum_score>=2:\n",
    "            curriculum_list.append(string)\n",
    "        if philosophy_score>=2:\n",
    "            philosophy_list.append(string)\n",
    "        if history_score>=2:\n",
    "            history_list.append(string)\n",
    "        if about_score>=2:\n",
    "            about_list.append(string)\n",
    "        elif (mission_score + curriculum_score + philosophy_score + history_score + about_score >=2):\n",
    "            about_list.append(string)\n",
    "        \n",
    "    #return {'mission': mission_list, 'curriculum' : curriculum_list, 'philosophy': philosophy_list, 'history': history_list, 'about': about_list}\n",
    "    return mission_list, curriculum_list, philosophy_list, history_list, about_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of categorize_page:\n",
      "\n",
      " (['Admissions', 'Mission', 'It is the mission of 21st Century Public Academy to continually search for positive learning experiences that enrich students and staff. Whenever possible, these lessons will take place in the arena in which they are practiced.'], ['21st Century is a charter middle school. We have been a school since 2000. We serve a diverse population of nearly 70 students per grade. All staff bring years of teaching experience into our classrooms, and many have worked together in other settings. We emphasize the core curriculum of Math, Science, Social Studies, and Language Arts, as well as learning experiences in the community, city, and state. Two Associated Arts courses are offered to each student every semester, including music and media programs.'], [], ['History'], ['Admissions', '21st Century is a charter middle school. We have been a school since 2000. We serve a diverse population of nearly 70 students per grade. All staff bring years of teaching experience into our classrooms, and many have worked together in other settings. We emphasize the core curriculum of Math, Science, Social Studies, and Language Arts, as well as learning experiences in the community, city, and state. Two Associated Arts courses are offered to each student every semester, including music and media programs.', 'History', 'Mission', 'It is the mission of 21st Century Public Academy to continually search for positive learning experiences that enrich students and staff. Whenever possible, these lessons will take place in the arena in which they are practiced.']) \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if Debug:\n",
    "    print(\"Output of categorize_page:\\n\\n\", categorize_page(example_textlist), \"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_categories(folder_path):\n",
    "    \n",
    "    \"\"\"Parse through all HTML files in foldername to find and save best pages for each category: \n",
    "    mission, curriculum, philosophy, history, about/general self-description.\"\"\"\n",
    "    \n",
    "    list_pages = [file for file in glob(folder_path + \"**\", recursive=True) if file.endswith(\".html\")] # Keep only HTML files\n",
    "    num_pages = len(list_pages)\n",
    "    max_page_score = (-1, -1)\n",
    "    \n",
    "    for i in range(num_pages):\n",
    "        page_text = parsefile_by_tags(list_pages[i])\n",
    "\n",
    "        if len(page_text) != 0:\n",
    "            page_score = dict_match(page_text, custom_dict) / len(page_text.split())\n",
    "            if page_score > max_page_score[0]:\n",
    "                max_page_score = (page_score, i)\n",
    "    max_text = open(filtered_file_format.format(max_page_score[1])).read()\n",
    "    \n",
    "    print(\"Page with the highest dictionary score:\\n\\n\" + max_text)\n",
    "    \n",
    "    return mission_page,curr_page,phil_page,hist_page,about_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Debug:\n",
    "    print(\"Output of find_best_categories:\\n\\n\", find_best_categories(example_folder), \"\\n\\n\" )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_school(school_dict, school_name, school_address, school_URL, datalocation, iter, numschools):\n",
    "    \n",
    "    \"\"\"This core function parses webtext for a given school, using helper functions to run analyses and then saving multiple outputs to school_dict:\n",
    "    full (partially cleaned) webtext, by parsing webtext of each .html file (removing inline tags, etc.) within school's folder, via parsefile_by_tags();\n",
    "    filtered webtext, by keeping only those parsed text elements containing a keyword in previously defined keywords list, via filter_keywords_page();\n",
    "    parsed webtext, having removed overlapping headers/footers common to multiple pages, via remove_overlaps();\n",
    "    all text associated with specific categories by filtering webtext according to keywords for \n",
    "    mission, curriculum, philosophy, history, and about/general self-description, via categorize_page(); and\n",
    "    contents of those individual pages best matching each of these categories, via find_best_categories.\"\"\"\n",
    "    \n",
    "    iter+=1\n",
    "    print(\"Parsing \" + str(school_name) + \", which is school #\" + str(iter) + \" of \" + str(numschools) + \"...\")\n",
    "    \n",
    "    school_dict['mission'],school_dict['curriculum'],school_dict['philosophy'],school_dict['history'],school_dict['about'] = \"\",\"\",\"\",\"\",\"\"\n",
    "    school_dict['mission_best'],school_dict['curriculum_best'],school_dict['philosophy_best'],school_dict['history_best'],school_dict['about_best'] = \"\",\"\",\"\",\"\",\"\"\n",
    "    school_dict[\"webtext\"], school_dict[\"filtered_text\"], school_dict[\"duplicate_flag\"], school_dict[\"parse_error_flag\"] = [], [], [], 0, 0\n",
    "    \n",
    "    folder_name = re.sub(\" \",\"_\",(name+\" \"+address[-8:-6]))\n",
    "    school_folder = datalocation + folder_name + \"/\"\n",
    "    \n",
    "    if school_URL not in parsed: #check if this URL has already been parsed. If so, skip this school to avoid duplication bias\n",
    "        parsed+=school_URL\n",
    "        \n",
    "        try:\n",
    "            for file in glob(school_folder + \"**\", recursive=True) if file.endswith(\".html\"): \n",
    "                # Parse file only if it contains HTML. This is easy: wget gave the \".html\" file extension to appropriate files when downloading\n",
    "                #if bool(BeautifulSoup(open(fname), bsparser).find())==True: # More inefficient way to check if file contains HTML, for data not downloaded by wget\n",
    "                if Debug:\n",
    "                    print(\"    Parsing HTML in \" + str(file) + \"...\")\n",
    "                try:                    \n",
    "                    parsed_pagetext = parsefile_by_tags(file) # Parse page text (filter too?)\n",
    "                    school_dict[\"webtext\"].extend(parsed_pagetext) # Add new parsed text to long list\n",
    "\n",
    "                    mission_text,curr_text,phil_text,hist_text,about_text = \"\",\"\",\"\",\"\",\"\" # Initialize new additions to school's categories\n",
    "                    mission_text,curr_text,phil_text,hist_text,about_text = categorize_page(parsed_pagetext) # Parse page text into the five categories\n",
    "                    school_dict['mission'].extend(mission_text) # Add new text to categories for school\n",
    "                    school_dict['curriculum'].extend(curr_text)\n",
    "                    school_dict['philosophy'].extend(phil_text)\n",
    "                    school_dict['history'].extend(hist_text)\n",
    "                    school_dict['about'].extend(about_text)\n",
    "                        \n",
    "                    school_dict[\"filtered_text\"].extend(filter_keywords_page(parsed_pagetext)) # Filter parsed file using keywords list\n",
    "                        \n",
    "                    if Debug:\n",
    "                        print(\"    Successfully parsed & categorized file...\\n\\n\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    if Debug:\n",
    "                        print(\"      ERROR! Failed to parse & categorize file...\")\n",
    "                        print(\"      \",e)\n",
    "                    else:\n",
    "                        continue\n",
    "                              \n",
    "            print(\"  Successfully parsed & categorized website text...\\n\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"    ERROR! Failed to parse & categorize webtext of \" + str(school_name))\n",
    "            print(\"    \",e)\n",
    "            school_dict[\"parse_error_flag\"] = 1\n",
    "    \n",
    "        try:\n",
    "            # Find and save best pages for each of the five categories:\n",
    "            mission_best,curr_best,phil_best,hist_best,about_best = \"\",\"\",\"\",\"\",\"\" # Initialize new dict elements\n",
    "            mission_best,curr_best,phil_best,hist_best,about_best = find_best_categories(school_folder) # Parse page text into the five categories\n",
    "            school_dict['mission_best'].extend(mission_best)\n",
    "            school_dict['curriculum_best'].extend(curr_best)\n",
    "            school_dict['philosophy_best'].extend(phil_best)\n",
    "            school_dict['history_best'].extend(hist_best)\n",
    "            school_dict['about_best'].extend(about_best)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"    ERROR! Failed to find best pages while parsing webtext of \" + str(school_name))\n",
    "            print(\"    \",e)\n",
    "            school_dict[\"parse_error_flag\"] = 1\n",
    "            return\n",
    "    \n",
    "    else:\n",
    "        print(\"DUPLICATE URL DETECTED. Skipping \" + str(school_name) + \"...\\n\\n\")\n",
    "        school_dict[\"duplicate_flag\"] = 1\n",
    "        return\n",
    "    \n",
    "    print(\"SUCCESS! Parsed and categorized website text for \" + str(school_name) + \"...\\n\\n\")\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Preparing data to be parsed\n",
    "\n",
    "# set charter school data file and corresponding varnames:\n",
    "if Debug:\n",
    "    data_loc = micro_sample13 # Run on micro-sample first, for debugging purposes\n",
    "else:\n",
    "    data_loc = full_schooldata # Run at scale using URL list of full charter population\n",
    "URL_var,NAME_var,ADDR_var = get_vars(data_loc) # get varnames depending on data source\n",
    "\n",
    "itervar = 0 # initialize iterator that counts number of schools already parsed\n",
    "parsed = [] # initialize list of URLs that have already been parsed\n",
    "dicts_list = [] # initialize list of dictionaries to hold school data\n",
    "\n",
    "# Create dict list from CSV on file, with one dict per school\n",
    "with open(data_loc, 'r', encoding = 'Latin1') as csvfile: # open data file\n",
    "    reader = csv.DictReader(csvfile) # create a reader\n",
    "    for row in reader: # loop through rows\n",
    "        dicts_list.append(row) # append each row to the list\n",
    "        \n",
    "# Note on data structures: each row, dicts_list[i] is a dictionary with keys as column name and value as info.\n",
    "# This will be translated into pandas data frame once (rather messy) website text is parsed into consistent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Run parsing algorithm on schools\n",
    "\n",
    "test_dicts = dicts_list[0] # Limit number of schools to analyze, in order to refine methods\n",
    "\n",
    "if Debug:\n",
    "    for school in test_dicts:\n",
    "        parse_school(school, school[NAME_var], school[ADDR_var], school[URL_var], data_loc, itervar, len(dicts_list))\n",
    "        \n",
    "else:\n",
    "    for school in dicts_list:\n",
    "        parse_school(school, school[NAME_var], school[ADDR_var], school[URL_var], data_loc, itervar, len(dicts_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out results:\n",
    "if Debug:\n",
    "    print(test_dicts[0])\n",
    "else:\n",
    "    print(dicts_list[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save output:\n",
    "if Debug:\n",
    "    dictfile = \"testing_dicts_\" + str(datetime.today())\n",
    "    save_to_file(test_dicts, save_dir+dictfile, \"JSON\")\n",
    "else:\n",
    "    dictfile = \"school_dicts_\" + str(datetime.today())\n",
    "    save_to_file(dicts_list, save_dir+dictfile, \"JSON\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
